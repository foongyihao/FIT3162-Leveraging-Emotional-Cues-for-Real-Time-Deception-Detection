{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8BqfahHa97Fs",
        "outputId": "19868566-c064-47f6-d270-cd45151c9d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/sberbank-ai/Real-ESRGAN.gitNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/sberbank-ai/Real-ESRGAN.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-4o3neyri'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Cloning https://github.com/sberbank-ai/Real-ESRGAN.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-4o3neyri\n",
            "  Resolved https://github.com/sberbank-ai/Real-ESRGAN.git to commit 362a0316878f41dbdfbb23657b450c3353de5acf\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from RealESRGAN==1.0) (2.0.1)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from RealESRGAN==1.0) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from RealESRGAN==1.0) (11.0.0)\n",
            "Requirement already satisfied: torch>=1.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from RealESRGAN==1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from RealESRGAN==1.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from RealESRGAN==1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from RealESRGAN==1.0) (0.14.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from torch>=1.7->RealESRGAN==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from torch>=1.7->RealESRGAN==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from torch>=1.7->RealESRGAN==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from torch>=1.7->RealESRGAN==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from torch>=1.7->RealESRGAN==1.0) (2025.3.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from torch>=1.7->RealESRGAN==1.0) (78.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.7->RealESRGAN==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from sympy==1.13.1->torch>=1.7->RealESRGAN==1.0) (1.3.0)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface-hub->RealESRGAN==1.0) (2.32.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface-hub->RealESRGAN==1.0) (6.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface-hub->RealESRGAN==1.0) (24.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from tqdm->RealESRGAN==1.0) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from jinja2->torch>=1.7->RealESRGAN==1.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface-hub->RealESRGAN==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface-hub->RealESRGAN==1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface-hub->RealESRGAN==1.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface-hub->RealESRGAN==1.0) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/sberbank-ai/Real-ESRGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xG-BMBwd97D2",
        "outputId": "a2e0b197-756e-463f-bc7c-ba345d3a8e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub==0.14.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (0.14.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (3.13.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (2025.3.2)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from huggingface_hub==0.14.1) (24.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub==0.14.1) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub==0.14.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (2.1.0)\n",
            "Collecting attrs>=19.1.0 (from mediapipe)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (24.12.23)\n",
            "Requirement already satisfied: jax in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.3)\n",
            "Collecting matplotlib (from mediapipe)\n",
            "  Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.2.0)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
            "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from jax->mediapipe) (1.15.0)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
            "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
            "  Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata (103 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
            "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\test\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
            "   ---------------- ----------------------- 6.3/15.5 MB 35.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.5/15.5 MB 40.7 MB/s eta 0:00:00\n",
            "Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
            "Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
            "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 8.1/8.1 MB 49.7 MB/s eta 0:00:00\n",
            "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
            "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.2/2.2 MB 41.0 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Installing collected packages: pyparsing, pycparser, protobuf, numpy, kiwisolver, fonttools, cycler, attrs, contourpy, CFFI, matplotlib\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.2\n",
            "    Uninstalling protobuf-5.29.2:\n",
            "      Successfully uninstalled protobuf-5.29.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.1\n",
            "    Uninstalling numpy-2.0.1:\n",
            "      Successfully uninstalled numpy-2.0.1\n",
            "Successfully installed CFFI-1.17.1 attrs-25.3.0 contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 numpy-1.26.4 protobuf-4.25.6 pycparser-2.22 pyparsing-3.2.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lOJPkbGO7ED",
        "outputId": "2339fa9d-2ba0-46b8-9cb4-6d68439c81a2"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1873669897.py, line 178)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 178\u001b[1;36m\u001b[0m\n\u001b[1;33m    video_filename = \"C:\\Users\\user\\Desktop\\Monash\\Y3S2\\FYP\\Code\\BF001_3NT.wmv\"  # Change this to your video\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import mediapipe as mp\n",
        "from PIL import Image\n",
        "import torch\n",
        "from RealESRGAN import RealESRGAN\n",
        "\n",
        "# Initialize Real-ESRGAN\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device:', device)\n",
        "model_scale = 2\n",
        "model = RealESRGAN(device, scale=model_scale)\n",
        "model.load_weights(f'weights/RealESRGAN_x{model_scale}.pth')\n",
        "\n",
        "def initialize_face_mesh():\n",
        "    \"\"\"Initialize and return the MediaPipe Face Mesh object.\"\"\"\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "    return mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
        "\n",
        "def create_output_directory(video_path):\n",
        "    \"\"\"Create output directory based on video filename within the current working directory.\"\"\"\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    current_dir = os.getcwd()\n",
        "    output_folder = os.path.join(current_dir, video_name)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    return output_folder\n",
        "\n",
        "def get_facial_landmarks(face_landmarks, img_w, img_h):\n",
        "    \"\"\"Extract key facial landmarks from MediaPipe results.\"\"\"\n",
        "    left_eye = np.array([int(face_landmarks.landmark[33].x * img_w), int(face_landmarks.landmark[33].y * img_h)])\n",
        "    right_eye = np.array([int(face_landmarks.landmark[263].x * img_w), int(face_landmarks.landmark[263].y * img_h)])\n",
        "    nose_tip = np.array([int(face_landmarks.landmark[4].x * img_w), int(face_landmarks.landmark[4].y * img_h)])\n",
        "    forehead_y = int(face_landmarks.landmark[10].y * img_h)\n",
        "    chin_y = int(face_landmarks.landmark[152].y * img_h)\n",
        "    return left_eye, right_eye, nose_tip, forehead_y, chin_y\n",
        "\n",
        "def compute_rotation_matrix(left_eye, right_eye, img_w, img_h):\n",
        "    \"\"\"Compute rotation matrix based on eye positions.\"\"\"\n",
        "    eye_delta_x = right_eye[0] - left_eye[0]\n",
        "    eye_delta_y = right_eye[1] - left_eye[1]\n",
        "    angle = np.degrees(np.arctan2(eye_delta_y, eye_delta_x))\n",
        "    center = (img_w // 2, img_h // 2)\n",
        "    return cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "def transform_landmarks(landmarks, rotation_matrix):\n",
        "    \"\"\"Transform landmarks using rotation matrix.\"\"\"\n",
        "    ones = np.ones((landmarks.shape[0], 1))\n",
        "    landmarks_homogeneous = np.hstack([landmarks, ones])\n",
        "    return np.dot(rotation_matrix, landmarks_homogeneous.T).T.astype(int)\n",
        "\n",
        "def calculate_face_bounding_box(transformed_landmarks, forehead_y, chin_y, img_w, img_h):\n",
        "    \"\"\"Calculate face bounding box with margins.\"\"\"\n",
        "    x_coords = transformed_landmarks[:, 0]\n",
        "    y_coords = transformed_landmarks[:, 1]\n",
        "    x_min, x_max = min(x_coords), max(x_coords)\n",
        "    # Add a margin for forehead and chin\n",
        "    forehead_margin = int(0.08 * img_h)\n",
        "    chin_margin = int(0.01 * img_h)\n",
        "    y_min = max(0, forehead_y - forehead_margin)\n",
        "    y_max = min(img_h, chin_y + chin_margin)\n",
        "    # Add padding\n",
        "    padding_x = int(0.02 * img_w)\n",
        "    padding_y = int(0.02 * img_h)\n",
        "    x_min = max(0, x_min - padding_x)\n",
        "    x_max = min(img_w, x_max + padding_x)\n",
        "    y_min = max(0, y_min - padding_y)\n",
        "    y_max = min(img_h, y_max + padding_y)\n",
        "    return x_min, y_min, x_max, y_max\n",
        "\n",
        "def transform_point(point, rotation_matrix):\n",
        "    \"\"\"Transform a single point using rotation matrix.\"\"\"\n",
        "    return np.dot(rotation_matrix, np.array([point[0], point[1], 1])).astype(int)\n",
        "\n",
        "def draw_landmarks_and_box(frame, x_min, y_min, x_max, y_max, t_left_eye, t_right_eye, t_nose_tip):\n",
        "    \"\"\"Draw bounding box and landmark lines on the frame.\"\"\"\n",
        "    # Draw bounding box\n",
        "    # cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "    # Optionally draw landmarks and connections:\n",
        "    # cv2.circle(frame, (t_left_eye[0], t_left_eye[1]), 3, (255, 0, 0), -1)\n",
        "    # cv2.circle(frame, (t_right_eye[0], t_right_eye[1]), 3, (255, 0, 0), -1)\n",
        "    # cv2.circle(frame, (t_nose_tip[0], t_nose_tip[1]), 3, (255, 0, 0), -1)\n",
        "    return frame\n",
        "\n",
        "def align_face(frame, face_landmarks, img_w, img_h):\n",
        "    \"\"\"Main function to align face and add visual elements.\"\"\"\n",
        "    left_eye, right_eye, nose_tip, forehead_y, chin_y = get_facial_landmarks(face_landmarks, img_w, img_h)\n",
        "    rotation_matrix = compute_rotation_matrix(left_eye, right_eye, img_w, img_h)\n",
        "    aligned_frame = cv2.warpAffine(frame, rotation_matrix, (img_w, img_h))\n",
        "    landmarks = np.array([(int(lm.x * img_w), int(lm.y * img_h)) for lm in face_landmarks.landmark])\n",
        "    transformed_landmarks = transform_landmarks(landmarks, rotation_matrix)\n",
        "    x_min, y_min, x_max, y_max = calculate_face_bounding_box(transformed_landmarks, forehead_y, chin_y, img_w, img_h)\n",
        "    t_left_eye = transform_point(left_eye, rotation_matrix)\n",
        "    t_right_eye = transform_point(right_eye, rotation_matrix)\n",
        "    t_nose_tip = transform_point(nose_tip, rotation_matrix)\n",
        "    aligned_frame = draw_landmarks_and_box(aligned_frame, x_min, y_min, x_max, y_max, t_left_eye, t_right_eye, t_nose_tip)\n",
        "    return aligned_frame\n",
        "\n",
        "def process_video(video_path, output_folder, target_frames=300, ssim_threshold=0.9):\n",
        "    \"\"\"Process video frames, align faces, crop the face, enhance quality, and save results.\"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    face_mesh = initialize_face_mesh()  # Initialize face landmark detector\n",
        "    saved_frames = []\n",
        "    last_face_crop = None\n",
        "    frame_count = 0\n",
        "\n",
        "    while video.isOpened():\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        try:\n",
        "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(rgb_frame)\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    img_h, img_w, _ = frame.shape\n",
        "                    aligned_frame = align_face(frame, face_landmarks, img_w, img_h)\n",
        "                    left_eye, right_eye, nose_tip, forehead_y, chin_y = get_facial_landmarks(face_landmarks, img_w, img_h)\n",
        "                    rotation_matrix = compute_rotation_matrix(left_eye, right_eye, img_w, img_h)\n",
        "                    landmarks = np.array([(int(lm.x * img_w), int(lm.y * img_h)) for lm in face_landmarks.landmark])\n",
        "                    transformed_landmarks = transform_landmarks(landmarks, rotation_matrix)\n",
        "                    x_min, y_min, x_max, y_max = calculate_face_bounding_box(transformed_landmarks, forehead_y, chin_y, img_w, img_h)\n",
        "                    face_crop = aligned_frame[y_min:y_max, x_min:x_max]\n",
        "                    face_crop_resized = cv2.resize(face_crop, (128, 128))\n",
        "\n",
        "                    if last_face_crop is not None:\n",
        "                        face_crop_gray = cv2.cvtColor(face_crop_resized, cv2.COLOR_BGR2GRAY)\n",
        "                        last_face_crop_gray = cv2.cvtColor(last_face_crop, cv2.COLOR_BGR2GRAY)\n",
        "                        ssim_score, _ = ssim(face_crop_gray, last_face_crop_gray, full=True)\n",
        "                        if ssim_score < ssim_threshold:\n",
        "                            saved_frames.append(face_crop_resized)\n",
        "                            last_face_crop = face_crop_resized\n",
        "                    else:\n",
        "                        saved_frames.append(face_crop_resized)\n",
        "                        last_face_crop = face_crop_resized\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame {frame_count}: {e}\")\n",
        "        frame_count += 1\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    total_frames = len(saved_frames)\n",
        "    if total_frames > target_frames:\n",
        "        indices = np.linspace(0, total_frames - 1, target_frames, dtype=int)\n",
        "        saved_frames = [saved_frames[i] for i in indices]\n",
        "    elif total_frames < target_frames:\n",
        "        if total_frames == 0:\n",
        "            print(\"No valid frames were saved. Check video input or face detection.\")\n",
        "            return frame_count, 0\n",
        "        indices = np.linspace(0, total_frames - 1, target_frames, dtype=int)\n",
        "        saved_frames = [saved_frames[i] for i in indices]\n",
        "\n",
        "    # Enhance image quality using Real-ESRGAN before saving\n",
        "    enhanced_frames = []\n",
        "    for idx, frame in enumerate(saved_frames):\n",
        "        try:\n",
        "            # Convert BGR (OpenCV) to RGB (PIL)\n",
        "            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            original_size = pil_image.size\n",
        "            sr_image = model.predict(np.array(pil_image))\n",
        "            sr_image = sr_image.resize(original_size, Image.LANCZOS)\n",
        "            sr_frame = cv2.cvtColor(np.array(sr_image), cv2.COLOR_RGB2BGR)\n",
        "            enhanced_frames.append(sr_frame)\n",
        "        except Exception as e:\n",
        "            print(f\"Error enhancing frame {idx}: {e}\")\n",
        "\n",
        "    # Save enhanced images\n",
        "    for idx, frame in enumerate(enhanced_frames):\n",
        "        output_path = os.path.join(output_folder, f'frame_{idx:04d}.png')\n",
        "        cv2.imwrite(output_path, frame)\n",
        "\n",
        "    return frame_count, len(enhanced_frames)\n",
        "\n",
        "\"\"\"Main function to orchestrate the face alignment process.\"\"\"\n",
        "video_filename = r\"C:\\Users\\user\\Desktop\\Monash\\Y3S2\\FYP\\Code\\BF001_3NT.wmv\" # Change this to your video\n",
        "output_folder = create_output_directory(video_filename)\n",
        "target_frames = 300  # Desired number of frames\n",
        "ssim_threshold = 0.9  # Adjust sensitivity if needed\n",
        "frame_count, saved_frame_count = process_video(video_filename, output_folder, target_frames, ssim_threshold)\n",
        "\n",
        "print(f\"Video filename: {video_filename}\")\n",
        "print(f\"Total frames processed: {frame_count}\")\n",
        "print(f\"Total frames saved: {saved_frame_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHKUmxsZ1UoJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12153d5918c54d03abb0bb0fbb223153": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1b74592bd34917b92990feb33723d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a90385cff7405f931704024ca995f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbfe38c3bbe64ab486f59a21d196268b",
              "IPY_MODEL_9922979b95244529952aac061cce5e09",
              "IPY_MODEL_e95a4d4a08764b869a641cb8f11f6a02"
            ],
            "layout": "IPY_MODEL_c22615e0aaa941f6803306f7f2fc2b82"
          }
        },
        "947a712d2d4a478fbbf5ec07968ff044": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9922979b95244529952aac061cce5e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12153d5918c54d03abb0bb0fbb223153",
            "max": 67061725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbc73cafda284c55b449a1ba797754cb",
            "value": 67061725
          }
        },
        "a3acac2e1be645948b4d5d960cd84914": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad16c07b03b4403299b66dbce0d34379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c22615e0aaa941f6803306f7f2fc2b82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc73cafda284c55b449a1ba797754cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e95a4d4a08764b869a641cb8f11f6a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1b74592bd34917b92990feb33723d9",
            "placeholder": "​",
            "style": "IPY_MODEL_ad16c07b03b4403299b66dbce0d34379",
            "value": " 67.1M/67.1M [00:00&lt;00:00, 252MB/s]"
          }
        },
        "fbfe38c3bbe64ab486f59a21d196268b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3acac2e1be645948b4d5d960cd84914",
            "placeholder": "​",
            "style": "IPY_MODEL_947a712d2d4a478fbbf5ec07968ff044",
            "value": "Downloading RealESRGAN_x2.pth: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
