{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [03:10<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-grained HOF preprocessing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_optical_flow(prev_frame, next_frame):\n",
    "    \"\"\"Computes dense optical flow using the Farneback method.\"\"\"\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY),\n",
    "        cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY),\n",
    "        None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
    "    )\n",
    "    return flow\n",
    "\n",
    "def compute_spatial_histograms(flow, num_mag_bins=50, num_angle_bins=72, grid_size=(4,4)):\n",
    "    \"\"\"Computes HOF histograms for spatially divided grid regions.\"\"\"\n",
    "    h, w, _ = flow.shape\n",
    "    grid_h, grid_w = h // grid_size[0], w // grid_size[1]\n",
    "    \n",
    "    hof_features = []\n",
    "    \n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            region = flow[i * grid_h: (i + 1) * grid_h, j * grid_w: (j + 1) * grid_w]\n",
    "            magnitude, angle = cv2.cartToPolar(region[..., 0], region[..., 1])\n",
    "            angle = np.degrees(angle) % 360  # Normalize angle to [0, 360] degrees\n",
    "            \n",
    "            mag_hist, _ = np.histogram(magnitude, bins=num_mag_bins, range=(0, np.max(magnitude)))\n",
    "            angle_hist, _ = np.histogram(angle, bins=num_angle_bins, range=(0, 360))\n",
    "            \n",
    "            mag_hist = mag_hist.astype(np.float32) / np.sum(mag_hist) if np.sum(mag_hist) > 0 else mag_hist\n",
    "            angle_hist = angle_hist.astype(np.float32) / np.sum(angle_hist) if np.sum(angle_hist) > 0 else angle_hist\n",
    "            \n",
    "            hof_features.extend(mag_hist)\n",
    "            hof_features.extend(angle_hist)\n",
    "    \n",
    "    return np.array(hof_features)\n",
    "\n",
    "def process_video_frames(frame_folder, num_mag_bins=50, num_angle_bins=72, grid_size=(4,4)):\n",
    "    \"\"\"Computes fine-grained HOF for a sequence of frames.\"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_folder))\n",
    "    num_frames = len(frame_files)\n",
    "\n",
    "    if num_frames < 2:\n",
    "        print(f\"Skipping {frame_folder}, not enough frames.\")\n",
    "        return None\n",
    "\n",
    "    combined_features = []\n",
    "    \n",
    "    for i in range(num_frames - 1):\n",
    "        frame1 = cv2.imread(os.path.join(frame_folder, frame_files[i]))\n",
    "        frame2 = cv2.imread(os.path.join(frame_folder, frame_files[i + 1]))\n",
    "        \n",
    "        if frame1 is None or frame2 is None:\n",
    "            continue\n",
    "\n",
    "        flow = compute_optical_flow(frame1, frame2)\n",
    "        hof_features = compute_spatial_histograms(flow, num_mag_bins, num_angle_bins, grid_size)\n",
    "        combined_features.append(hof_features)\n",
    "    \n",
    "    return np.array(combined_features)\n",
    "\n",
    "def preprocess_dataset(dataset_path, output_path, num_mag_bins=30, num_angle_bins=36, grid_size=(4,4)):\n",
    "    \"\"\"Processes dataset and saves HOF features.\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    for sample_folder in tqdm(os.listdir(dataset_path)):\n",
    "        sample_path = os.path.join(dataset_path, sample_folder)\n",
    "        \n",
    "        if not os.path.isdir(sample_path):\n",
    "            continue\n",
    "        \n",
    "        combined_features = process_video_frames(sample_path, num_mag_bins, num_angle_bins, grid_size)\n",
    "        \n",
    "        if combined_features is not None:\n",
    "            output_file = os.path.join(output_path, f\"{sample_folder}_hof.npy\")\n",
    "            np.save(output_file, combined_features)\n",
    "\n",
    "# Paths\n",
    "dataset_path = \"../dataset_100_3_points\"  # Update with actual path\n",
    "output_path = \"../precomputed_hof_100\"\n",
    "\n",
    "# Run preprocessing\n",
    "preprocess_dataset(dataset_path, output_path)\n",
    "print(\"Fine-grained HOF preprocessing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 320/320 [09:50<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation and HOF preprocessing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import random\n",
    "\n",
    "def apply_augmentations(frame):\n",
    "    \"\"\"Applies random augmentations to the given frame.\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        frame = cv2.flip(frame, 1)  # Horizontal flip\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        factor = random.uniform(0.8, 1.2)  # Random brightness\n",
    "        frame = np.clip(frame * factor, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        noise = np.random.normal(0, 10, frame.shape).astype(np.uint8)  # Gaussian noise\n",
    "        frame = np.clip(frame + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        angle = random.uniform(-10, 10)  # Random rotation\n",
    "        h, w = frame.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "        frame = cv2.warpAffine(frame, M, (w, h))\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def compute_optical_flow(prev_frame, next_frame):\n",
    "    gray1 = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow\n",
    "\n",
    "def compute_spatial_histograms(flow, num_mag_bins=30, num_angle_bins=36, grid_size=(4,4), smooth_sigma=1.0):\n",
    "    h, w, _ = flow.shape\n",
    "    grid_h, grid_w = h // grid_size[0], w // grid_size[1]\n",
    "    hof_features = []\n",
    "    \n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            region = flow[i * grid_h: (i + 1) * grid_h, j * grid_w: (j + 1) * grid_w]\n",
    "            magnitude, angle = cv2.cartToPolar(region[..., 0], region[..., 1])\n",
    "            angle = np.degrees(angle) % 360  \n",
    "\n",
    "            mag_hist, _ = np.histogram(magnitude, bins=num_mag_bins, range=(0, np.max(magnitude) if np.max(magnitude) > 0 else 1))\n",
    "            angle_hist, _ = np.histogram(angle, bins=num_angle_bins, range=(0, 360))\n",
    "\n",
    "            mag_hist = mag_hist / (np.sum(mag_hist) + 1e-6)\n",
    "            angle_hist = angle_hist / (np.sum(angle_hist) + 1e-6)\n",
    "\n",
    "            mag_hist = gaussian_filter1d(mag_hist, sigma=smooth_sigma)\n",
    "            angle_hist = gaussian_filter1d(angle_hist, sigma=smooth_sigma)\n",
    "\n",
    "            hof_features.extend(mag_hist)\n",
    "            hof_features.extend(angle_hist)\n",
    "    \n",
    "    return np.array(hof_features, dtype=np.float32)\n",
    "\n",
    "def process_video_frames(frame_folder, num_aug=2):\n",
    "    frame_files = sorted(os.listdir(frame_folder))\n",
    "    num_frames = len(frame_files)\n",
    "    \n",
    "    if num_frames < 2:\n",
    "        return None, None, None\n",
    "\n",
    "    original_features = []\n",
    "    augmented_features_1 = []\n",
    "    augmented_features_2 = []\n",
    "    \n",
    "    for i in range(num_frames - 1):\n",
    "        frame1 = cv2.imread(os.path.join(frame_folder, frame_files[i]))\n",
    "        frame2 = cv2.imread(os.path.join(frame_folder, frame_files[i + 1]))\n",
    "        \n",
    "        if frame1 is None or frame2 is None:\n",
    "            continue\n",
    "\n",
    "        # Original optical flow\n",
    "        flow = compute_optical_flow(frame1, frame2)\n",
    "        hof_features = compute_spatial_histograms(flow)\n",
    "        original_features.append(hof_features)\n",
    "\n",
    "        # Augmentation 1\n",
    "        aug_frame1 = apply_augmentations(frame1.copy())\n",
    "        aug_frame2 = apply_augmentations(frame2.copy())\n",
    "        aug_flow1 = compute_optical_flow(aug_frame1, aug_frame2)\n",
    "        aug_hof_features1 = compute_spatial_histograms(aug_flow1)\n",
    "        augmented_features_1.append(aug_hof_features1)\n",
    "\n",
    "        # Augmentation 2\n",
    "        aug_frame1 = apply_augmentations(frame1.copy())\n",
    "        aug_frame2 = apply_augmentations(frame2.copy())\n",
    "        aug_flow2 = compute_optical_flow(aug_frame1, aug_frame2)\n",
    "        aug_hof_features2 = compute_spatial_histograms(aug_flow2)\n",
    "        augmented_features_2.append(aug_hof_features2)\n",
    "\n",
    "    return np.array(original_features), np.array(augmented_features_1), np.array(augmented_features_2)\n",
    "\n",
    "def preprocess_dataset(dataset_path, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    for sample_folder in tqdm(os.listdir(dataset_path), desc=\"Processing videos\"):\n",
    "        sample_path = os.path.join(dataset_path, sample_folder)\n",
    "        if not os.path.isdir(sample_path):\n",
    "            continue\n",
    "\n",
    "        original, aug1, aug2 = process_video_frames(sample_path, num_aug=2)\n",
    "        \n",
    "        if original is not None and len(original) > 0:\n",
    "            np.save(os.path.join(output_path, f\"{sample_folder}_hof.npy\"), original)\n",
    "            np.save(os.path.join(output_path, f\"{sample_folder}_aug1_hof.npy\"), aug1)\n",
    "            np.save(os.path.join(output_path, f\"{sample_folder}_aug2_hof.npy\"), aug2)\n",
    "\n",
    "# Paths\n",
    "dataset_path = \"../dataset_100_3_points\"\n",
    "output_path = \"../precomputed_hof_augmented_100\"\n",
    "\n",
    "# Run preprocessing\n",
    "preprocess_dataset(dataset_path, output_path)\n",
    "print(\"Data augmentation and HOF preprocessing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 320/320 [20:23<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation and HOF preprocessing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import random\n",
    "\n",
    "def apply_augmentations(frame):\n",
    "    \"\"\"Applies random augmentations to the given frame.\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        frame = cv2.flip(frame, 1)  # Horizontal flip\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        factor = random.uniform(0.8, 1.2)  # Random brightness\n",
    "        frame = np.clip(frame * factor, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        noise = np.random.normal(0, 10, frame.shape).astype(np.uint8)  # Gaussian noise\n",
    "        frame = np.clip(frame + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        angle = random.uniform(-10, 10)  # Random rotation\n",
    "        h, w = frame.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "        frame = cv2.warpAffine(frame, M, (w, h))\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def compute_optical_flow(prev_frame, next_frame):\n",
    "    gray1 = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow\n",
    "\n",
    "def compute_spatial_histograms(flow, num_mag_bins=30, num_angle_bins=36, grid_size=(4,4), smooth_sigma=1.0):\n",
    "    h, w, _ = flow.shape\n",
    "    grid_h, grid_w = h // grid_size[0], w // grid_size[1]\n",
    "    hof_features = []\n",
    "    \n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            region = flow[i * grid_h: (i + 1) * grid_h, j * grid_w: (j + 1) * grid_w]\n",
    "            magnitude, angle = cv2.cartToPolar(region[..., 0], region[..., 1])\n",
    "            angle = np.degrees(angle) % 360  \n",
    "\n",
    "            mag_hist, _ = np.histogram(magnitude, bins=num_mag_bins, range=(0, np.max(magnitude) if np.max(magnitude) > 0 else 1))\n",
    "            angle_hist, _ = np.histogram(angle, bins=num_angle_bins, range=(0, 360))\n",
    "\n",
    "            mag_hist = mag_hist / (np.sum(mag_hist) + 1e-6)\n",
    "            angle_hist = angle_hist / (np.sum(angle_hist) + 1e-6)\n",
    "\n",
    "            mag_hist = gaussian_filter1d(mag_hist, sigma=smooth_sigma)\n",
    "            angle_hist = gaussian_filter1d(angle_hist, sigma=smooth_sigma)\n",
    "\n",
    "            hof_features.extend(mag_hist)\n",
    "            hof_features.extend(angle_hist)\n",
    "    \n",
    "    return np.array(hof_features, dtype=np.float32)\n",
    "\n",
    "def process_video_frames(frame_folder, num_aug=4):\n",
    "    frame_files = sorted(os.listdir(frame_folder))\n",
    "    num_frames = len(frame_files)\n",
    "    \n",
    "    if num_frames < 2:\n",
    "        return None, None\n",
    "\n",
    "    original_features = []\n",
    "    augmented_features = [[] for _ in range(num_aug)]\n",
    "    \n",
    "    for i in range(num_frames - 1):\n",
    "        frame1 = cv2.imread(os.path.join(frame_folder, frame_files[i]))\n",
    "        frame2 = cv2.imread(os.path.join(frame_folder, frame_files[i + 1]))\n",
    "        \n",
    "        if frame1 is None or frame2 is None:\n",
    "            continue\n",
    "\n",
    "        # Original optical flow\n",
    "        flow = compute_optical_flow(frame1, frame2)\n",
    "        hof_features = compute_spatial_histograms(flow)\n",
    "        original_features.append(hof_features)\n",
    "\n",
    "        # Generate multiple augmentations\n",
    "        for j in range(num_aug):\n",
    "            aug_frame1 = apply_augmentations(frame1.copy())\n",
    "            aug_frame2 = apply_augmentations(frame2.copy())\n",
    "            aug_flow = compute_optical_flow(aug_frame1, aug_frame2)\n",
    "            aug_hof_features = compute_spatial_histograms(aug_flow)\n",
    "            augmented_features[j].append(aug_hof_features)\n",
    "\n",
    "    return np.array(original_features), [np.array(aug) for aug in augmented_features]\n",
    "\n",
    "def preprocess_dataset(dataset_path, output_path, num_aug=4):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    for sample_folder in tqdm(os.listdir(dataset_path), desc=\"Processing videos\"):\n",
    "        sample_path = os.path.join(dataset_path, sample_folder)\n",
    "        if not os.path.isdir(sample_path):\n",
    "            continue\n",
    "\n",
    "        original, augmentations = process_video_frames(sample_path, num_aug=num_aug)\n",
    "        \n",
    "        if original is not None and len(original) > 0:\n",
    "            np.save(os.path.join(output_path, f\"{sample_folder}_hof.npy\"), original)\n",
    "            for j in range(num_aug):\n",
    "                np.save(os.path.join(output_path, f\"{sample_folder}_aug{j+1}_hof.npy\"), augmentations[j])\n",
    "\n",
    "# Paths\n",
    "dataset_path = \"../dataset_200_3_points\"\n",
    "output_path = \"../precomputed_hof_augmented_200\"\n",
    "\n",
    "# Run preprocessing\n",
    "preprocess_dataset(dataset_path, output_path, num_aug=2)\n",
    "print(\"Data augmentation and HOF preprocessing completed!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
